@online{Lawis:2022,
  author = {Lawinenwarndienst Tirol, Lawinenwarndienst Steiermark, Lawinenwarndienst Salzburg, Lawinenwarndienst Oberösterreich, Lawinenwarndienst Vorarlberg, Lawinenwarndienst Kärnten, Universität Wien},
  title = {{Lawinen Ereignisse}},
  year = 2022,
  url = {https://lawis.at/incident/},
  urldate = {2022-01-10}
}

@online{Verbund:2022,
titel = {{über Verbund}},
year = 2022,
url = {https://www.verbund.com/de-at/ueber-verbund},
urldate = {2022-04-01}
}

@online{Scikit-learn-decision-tree:2022,
titel = {{Decision Trees}},
year = 2022,
url = {https://scikit-learn.org/stable/modules/tree.html},
urldate = {2022-04-13}
}

@online{Scikit-learn-logistic-regression:2022,
titel = {{sklearn.linear_model.LogisticRegression}},
year = 2022,
url = {https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn-linear-model-logisticregression},
urldate = {2022-05-21}
}
@online{ibm-logistic-regression:2022,
titel = {{What is logistic regression?}},
year = 2022,
url = {https://www.ibm.com/topics/logistic-regression},
urldate = {2022-05-21}
}


@online{VerbundKaprun:2022,
titel = {{Verbund Kaprun}},
year = 2022,
url = {https://www.verbund.com/de-at/ueber-verbund/besucherzentren/kaprun},
urldate = {2022-04-05}
}



@incollection{SUBASI202091,
	abstract = {Machine learning uses the theory of statistics to build mathematical models, as the main objective is to yield inferences from a sample. Once a model is built, its representation and algorithmic solution for interpretation needs to be competent as well. In some applications, the competence of the machine learning algorithm might be as important as its classification accuracy. Machine learning is used in several fields, including forecasting, anomaly detection, and biomedical data analysis as a decision support element. The purpose of this chapter is to help scientists select an appropriate machine learning technique and guide them using optimal strategies by employing real-time databases, in addition to familiarizing readers with the basics of machine learning before taking a deep dive into solving real-world problems with machine learning techniques. Basic concepts are covered in areas such as artificial intelligence, data mining, computer science, data science, natural language processing, deep learning, mathematics, and statistics. Topics related to the various machine learning techniques will be explored, including supervised, unsupervised, and reinforcement learning, hence important machine learning algorithms are discussed in this chapter. Toward the end of every section, suitable Python functions will be illustrated as examples. Most of the examples are taken from Python--scikit-learn library (https://scikit-learn.org/stable/) and TensorFlow, and then adapted.},
	author = {Abdulhamit Subasi},
	booktitle = {Practical Machine Learning for Data Analysis Using Python},
	doi = {https://doi.org/10.1016/B978-0-12-821379-7.00003-5},
	editor = {Abdulhamit Subasi},
	isbn = {978-0-12-821379-7},
	keywords = {linear discriminant analysis (LDA), k-nearest neighbour (k-NN), artificial neural networks (ANN), support vector machines (SVM), decision tree algorithm, deep learning, clustering},
	pages = {91-202},
	publisher = {Academic Press},
	title = {Chapter 3 - Machine learning techniques},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128213797000035},
	year = {2020},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/B9780128213797000035},
	bdsk-url-2 = {https://doi.org/10.1016/B978-0-12-821379-7.00003-5}}



@incollection{BELYADI2021169,
	abstract = {This chapter covers the theory, step-by-step codes, and applications of various supervised learning algorithms including multilinear regression, logistic regression, k-nearest neighbor (KNN), support vector machine (SVM), decision tree, random forest, extra trees, gradient boosting, extreme gradient boosting, and adaptive gradient boosting using scikit-learn. Various machine learning (ML) applications in the oil and gas industry, including productivity effectiveness, binary classification of ML application in geomechanical log property prediction (shear wave and compression wave travel time predictions), TOC prediction, net present value prediction, frac intensity binary classification, and rate of penetration prediction, have been detailed and illustrated in an easy workflow in Python. Finally, handling missing data using the effective impute package library in Python is discussed. K-nearest neighbor, iterative imputer, and multivariate imputation by chained equations (MICE) are illustrated with the step-by-step codes in Python. These techniques were applied to impute the missing values in a frac stage data set. The examples and guidelines shown in this chapter can be easily applied to solve various other oil and gas--related problems.},
	author = {Hoss Belyadi and Alireza Haghighat},
	booktitle = {Machine Learning Guide for Oil and Gas Using Python},
	doi = {https://doi.org/10.1016/B978-0-12-821929-4.00004-4},
	editor = {Hoss Belyadi and Alireza Haghighat},
	isbn = {978-0-12-821929-4},
	keywords = {Adaptive gradient boosting, Decision tree, Extra trees, Extreme gradient boosting, Frac intensity prediction, Geomechanical log prediction, Gradient boosting, K-nearest neighbor (KNN), Logistic regression, Missing data imputation of frac data, Multilinear regression, Net present value prediction, Productivity prediction, Random forest, ROP prediction, Support vector machine (SVM), TOC prediction},
	pages = {169-295},
	publisher = {Gulf Professional Publishing},
	title = {Chapter 5 - Supervised learning},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128219294000044},
	year = {2021},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/B9780128219294000044},
	bdsk-url-2 = {https://doi.org/10.1016/B978-0-12-821929-4.00004-4}}





@article{Sourav:2020,
abstract = {Linear Regression is a commonly used supervised Machine Learning algorithm that predicts continuous values. Linear Regression assumes that there is a linear relationship present between dependent and independent variables. In simple words, it finds the best fitting line/plane that describes two or more variables.

On the other hand, Logistic Regression is another supervised Machine Learning algorithm that helps fundamentally in binary classification (separating discreet values).

Although the usage of Linear Regression and Logistic Regression algorithm is completely different, mathematically we can observe that with an additional step we can convert Linear Regression into Logistic Regression.},
title = {{Beginners Take: How Logistic Regression is related to Linear Regression}},
journal = {Data Science Blogathon},
year = 2020,
month = dez,
  day = 1,
url = {https://www.analyticsvidhya.com/blog/2020/12/beginners-take-how-logistic-regression-is-related-to-linear-regression/},
}

@article{NUSINOVICI202056,
	abstract = {Objective
To evaluate the performance of machine learning (ML) algorithms and to compare them with logistic regression for the prediction of risk of cardiovascular diseases (CVDs), chronic kidney disease (CKD), diabetes (DM), and hypertension (HTN) and in a prospective cohort study using simple clinical predictors.
Study Design and Setting
We conducted analyses in a population-based cohort study in Asian adults (n = 6,762). Five different ML models were considered---single-hidden-layer neural network, support vector machine, random forest, gradient boosting machine, and k-nearest neighbor---and were compared with standard logistic regression.
Results
The incidences at 6 years of CVD, CKD, DM, and HTN cases were 4.0%, 7.0%, 9.2%, and 34.6%, respectively. Logistic regression reached the highest area under the receiver operating characteristic curve for CKD (0.905 [0.88, 0.93]) and DM (0.768 [0.73, 0.81]) predictions. For CVD and HTN, the best models were neural network (0.753 [0.70, 0.81]) and support vector machine (0.780 [0.747, 0.812]), respectively. However, the differences with logistic regression were small (less than 1%) and nonsignificant. Logistic regression, gradient boosting machine, and neural network were systematically ranked among the best models.
Conclusion
Logistic regression yields as good performance as ML models to predict the risk of major chronic diseases with low incidence and simple clinical predictors.},
	author = {Simon Nusinovici and Yih Chung Tham and Marco Yu {Chak Yan} and Daniel Shu {Wei Ting} and Jialiang Li and Charumathi Sabanayagam and Tien Yin Wong and Ching-Yu Cheng},
	doi = {https://doi.org/10.1016/j.jclinepi.2020.03.002},
	issn = {0895-4356},
	journal = {Journal of Clinical Epidemiology},
	keywords = {Machine learning, Logistic regression, Prognostic modeling, Chronic diseases, Interaction, Nonlinearity},
	pages = {56-69},
	title = {Logistic regression was as good as machine learning for predicting major chronic diseases},
	url = {https://www.sciencedirect.com/science/article/pii/S0895435619310194},
	volume = {122},
	year = {2020},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0895435619310194},
	bdsk-url-2 = {https://doi.org/10.1016/j.jclinepi.2020.03.002}}



@article{LU2008887,
	abstract = {Machine learning techniques for feature selection, which include the optimization of feature descriptor weights and the selection of optimal feature descriptor subset, are desirable to enhance the performance of image annotation systems. In our system, the multimedia content description interface (MPEG-7) image feature descriptors consisting of color descriptors, texture descriptors and shape descriptors are employed to represent low-level image features. We use a real coded chromosome genetic algorithm and k-nearest neighbor (k-NN) classification accuracy as fitness function to optimize the weights of MPEG-7 image feature descriptors. A binary one and k-NN classification accuracy combining with the size of feature descriptor subset as fitness function are used to select optimal MPEG-7 feature descriptor subset. Furthermore, a bi-coded chromosome genetic algorithm is used for the simultaneity of weight optimization and descriptor subset selection, whose fitness function is the same as that of the binary one. The experimental results over 2000 classified Corel images show that with the real coded genetic algorithm, the binary coded one and the bi-coded one, the accuracies of image annotation system are improved by 7%, 9% and 13.6%, respectively, comparing to the method without machine learning. Furthermore, 2 of 25 MPEG-7 feature descriptors are selected with the binary coded genetic algorithm and four with the bi-coded one, which may improve the efficiency of system significantly.},
	author = {Jianjiang Lu and Tianzhong Zhao and Yafei Zhang},
	doi = {https://doi.org/10.1016/j.knosys.2008.03.051},
	issn = {0950-7051},
	journal = {Knowledge-Based Systems},
	keywords = {Image annotation, Feature selection, Genetic algorithm, -Nearest neighbor classifier, Multimedia content description interface},
	number = {8},
	pages = {887-891},
	title = {Feature selection based-on genetic algorithm for image annotation},
	url = {https://www.sciencedirect.com/science/article/pii/S095070510800097X},
	volume = {21},
	year = {2008},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S095070510800097X},
	bdsk-url-2 = {https://doi.org/10.1016/j.knosys.2008.03.051}}



@article{Yang:2018
	author = {Tao-Chang Yang, Pao-Shan Yu, Kun-Hsiang Lin, Chen-Min Kuo, Hung-Wei Tseng},
	title = {Predictor selection method for the construction of support vector machine (SVM)-based typhoon rainfall forecasting models using a non-dominated sorting genetic algorithm},
	abstract = {This study proposes a predictor selection method for constructing a support vector machine (SVM)-based typhoon rainfall forecasting models using a fast elitist Non-dominated Sorting Genetic Algorithm II (NSGA-II). Based on SVMs, four rainfall forecasting models with different combinations of the three types of input variables (i.e. antecedent rainfalls, typhoon characteristics and local weather factors) were constructed for 1–6 hr-ahead forecasting. An application to three rain gauge stations in the Yilan River basin, northeastern Taiwan, was conducted to demonstrate the superiority of the proposed predictor selection method. The results showed that the optimal combination of predictors for each SVM-based rainfall forecasting model can be automatically and effectively determined by the proposed predictor selection method. The rainfall forecasting model using all three types of input variables performed better than the other three models, especially for long lead-time forecasting. The construction of rainfall forecasting models is helpful to extend the lead time of flood forecasting. The optimal rainfall forecasting model can be further integrated with river hydraulic models or flood inundation models for flood forecasting to assist floodplain managers to take suitable precautionary measures during typhoon landfall.},
	journal = {Meteorological Applications},
	volume = {25},
	year = {2018},
	doi = {https://doi.org/10.1002/met.1717},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.1717}

}


@article{DBLP:1912,
  author    = {Petro Liashchynskyi and
               Pavlo Liashchynskyi},
  title     = {Grid Search, Random Search, Genetic Algorithm: {A} Big Comparison
               for {NAS}},
  journal   = {CoRR},
  volume    = {abs/1912.06059},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.06059},
  eprinttype = {arXiv},
  eprint    = {1912.06059},
  timestamp = {Thu, 02 Jan 2020 18:08:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-06059.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{VenkateshAnuradha:2019,
	author = {B. Venkatesh and J. Anuradha},
	doi = {doi:10.2478/cait-2019-0001},
	journal = {Cybernetics and Information Technologies},
	number = {1},
	pages = {3--26},
	title = {A Review of Feature Selection and Its Methods},
	url = {https://doi.org/10.2478/cait-2019-0001},
	volume = {19},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.2478/cait-2019-0001}}

@article{ALLAM2022329,
	abstract = {Feature selection is a significant task in the workflow of predictive modeling for data analysis. Recent advanced feature selection methods are using the power of optimization algorithms for choosing a subset of relevant features to get better classification results. Most of the optimization algorithms like genetic algorithm use many controlling parameters which need to be tuned for better performance. Tuning these parameter values is a challenging task for the feature selection process. In this paper, we have developed a new wrapper-based feature selection method called binary teaching learning based optimization (FS-BTLBO) algorithm which needs only common controlling parameters like population size, and a number of generations to obtain a subset of optimal features from the dataset. We have used different classifiers as an objective function to compute the fitness of individuals for evaluating the efficiency of the proposed system. The results have proven that FS-BTLBO produces higher accuracy with a minimal number of features on Wisconsin diagnosis breast cancer (WDBC) data set to classify malignant and benign tumors.},
	author = {Mohan Allam and M. Nandhini},
	doi = {https://doi.org/10.1016/j.jksuci.2018.12.001},
	issn = {1319-1578},
	journal = {Journal of King Saud University - Computer and Information Sciences},
	keywords = {Feature selection, Binary teaching learning based optimization, Genetic algorithm, Breast cancer},
	number = {2},
	pages = {329-341},
	title = {Optimal feature selection using binary teaching learning based optimization algorithm},
	url = {https://www.sciencedirect.com/science/article/pii/S1319157818306463},
	volume = {34},
	year = {2022},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S1319157818306463},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.jksuci.2018.12.001}}


@article{SUGUMARAN2007930,
	abstract = {Roller bearing is one of the most widely used rotary elements in a rotary machine. The roller bearing's nature of vibration reveals its condition and the features that show the nature, are to be extracted through some indirect means. Statistical parameters like kurtosis, standard deviation, maximum value, etc. form a set of features, which are widely used in fault diagnostics. Often the problem is, finding out good features that discriminate the different fault conditions of the bearing. Selection of good features is an important phase in pattern recognition and requires detailed domain knowledge. This paper illustrates the use of a Decision Tree that identifies the best features from a given set of samples for the purpose of classification. It uses Proximal Support Vector Machine (PSVM), which has the capability to efficiently classify the faults using statistical features. The vibration signal from a piezoelectric transducer is captured for the following conditions: good bearing, bearing with inner race fault, bearing with outer race fault, and inner and outer race fault. The statistical features are extracted therefrom and classified successfully using PSVM and SVM. The results of PSVM and SVM are compared.},
	author = {V. Sugumaran and V. Muralidharan and K.I. Ramachandran},
	doi = {https://doi.org/10.1016/j.ymssp.2006.05.004},
	issn = {0888-3270},
	journal = {Mechanical Systems and Signal Processing},
	keywords = {Feature selection, Decision Tree, Roller bearing, Statistical features, PSVM, Fault detection},
	number = {2},
	pages = {930-942},
	title = {Feature selection using Decision Tree and classification through Proximal Support Vector Machine for fault diagnostics of roller bearing},
	url = {https://www.sciencedirect.com/science/article/pii/S0888327006001142},
	volume = {21},
	year = {2007},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S0888327006001142},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ymssp.2006.05.004}}


@article{Martin:2001,
abstract = {The SAFRAN/Crocus/MÉPRA software is used to assess the climatology of the avalanche hazard and its sensitivity to climate change. A natural avalanche-hazard index based on MEPRA analysis is defined and validated against natural avalanche observations (triggered avalanches are not taken into account). A 15 year climatology then allows a comparison of avalanche hazard in the different French massifs. Finally a simple climate scenario (with a general increase of precipitation and temperature) shows that avalanche hazard may decrease slightly in winter (mainly February) and more significantly in May/June. The relative proportion of wet-snow avalanches increases.},
author = {Eric Martin, Gérald Giraud, Yves Lejeune, Géraldine Boudart},
journal = {Annals of Glaciology},
pages = {163--167},
volume = {32},
title = {{Impact of a climate change on avalanche hazard}},
year = {2001},
url = {https://doi.org/10.3189/172756401781819292}
}


@article{Bahram:2019,
abstract = {Snow avalanches are among the most destructive natural hazards threatening human life, ecosystems, built structures, and landscapes in mountainous regions. The complexity of snow avalanche modelling has been discussed in many studies, but its modelling is not well-documented. Snow avalanche modeling in this study was done using three main categories of data, including avalanche occurrence locations, meteorological factors, and terrain characteristics. Two machine learning models, namely support vector machine (SVM) and multivariate discriminant analysis (MDA), were employed. A ratio of 70 to 30 of data was considered for calibrating and validating the models. Results indicated that both models had an excellent performance in snow avalanche modeling (area under curve, AUC > 90), although hits and misses analysis demonstrated the superior performance of MDA. Sensitivity analysis indicated that the topographic position index, slope, precipitation, and topographic wetness index were the most effective variables for modeling. A snow avalanche map indicated that the high snow avalanche hazard zone was mostly near the streams and was matched with hillsides around the water pathways. Findings of study can be helpful for land use planning, to control snow avalanche paths, and to prevent the probable hazards induced by it, and it can be a good reference for future studies on modeling snow avalanche hazards.},
author = {Bahram Choubin, Moslem Borji, Amir Mosavi, Farzaneh Sajedi-Hosseini, Vijay P.Singh, Shahaboddin Shamshirband},
journal = {Journal of Hydrology},
volume = {577},
title = {{Snow avalanche hazard prediction using machine learning methods}},
year = {2019},
url = {https://doi.org/10.1016/j.jhydrol.2019.123929}
}

@article{Tiwari:2021,
abstract = {Due to ongoing climate change, water mass redistribution and related hazards are getting stronger and frequent. Therefore, predicting extreme hydrological events and related hazards is one of the highest priorities in geosciences. Machine Learning (ML) methods have shown promising prospects in this venture. Every ML method requires training where we know both the output (extreme event) and input (relevant physical parameters and variables). This step is critical to the efficacy of the ML method. The usual approach is to include a wide variety of hydro-meteorological observations and physical parameters, but recent advances in ML indicate that the efficacy of ML may not improve by increasing the number of input parameters. In fact, including unimportant parameters decreases the efficacy of ML algorithms. Therefore, it is imperative that the most relevant parameters are identified prior to training. In this study, we demonstrate this concept by predicting avalanche susceptibility in Leh-Manali highway (one of the most severely affected regions in India) with and without Parameter Importance Assessment (PIA). The avalanche locations were randomly divided into two groups: 70% for training and 30% for testing. Then, based on temporal and spatial sensor data, eleven avalanche influencing parameters were considered. The Boruta algorithm, an extension of Random Forest (RF) ML method that utilizes the importance measure to rank predictors, was used and it found nine out of eleven parameters to be important. Support Vector Machine (SVM) based ML technique is used for avalanche prediction, and to be comprehensive, four different kernel functions were employed (linear, polynomial, sigmoid, and radial basis function (RBF)). The prediction accuracy for linear, polynomial, sigmoid, and RBF kernels, with all the eleven parameters were found to be 80.4%, 81.7%, 39.2%, and 85.7%, respectively. While, when using selected parameters, the prediction accuracy for linear, polynomial, sigmoid, and RBF kernels were 84.1%, 86.6%, 43.0%, and 87.8%, respectively. We also identified locations where occurrences of avalanches are most likely. We conclude that parameter selection should be considered when applying ML methods in geosciences.},
author = {Anuj Tiwari, Arun G., Bramha Dutt, Vishwakarma},
journal = {Science of The Total Environment},
volume = {794},
title = {Parameter importance assessment improves efficacy of machine learning methods for predicting snow avalanche sites in Leh-Manali Highway, India},
year = {2021},
url = {https://doi.org/10.1016/j.scitotenv.2021.148738}
}

@article{THURING201560,
title = {Robust snow avalanche detection using supervised machine learning with infrasonic sensor arrays},
journal = {Cold Regions Science and Technology},
volume = {111},
pages = {60-66},
year = {2015},
issn = {0165-232X},
doi = {https://doi.org/10.1016/j.coldregions.2014.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0165232X14002419},
author = {Thomas Thüring and Marcel Schoch and Alec {van Herwijnen} and Jürg Schweizer},
keywords = {Snow avalanches, Infrasound, Array processing, Automated monitoring, Machine learning},
abstract = {Automated detection of snow avalanches is crucial to assess the effectiveness of avalanche control by explosions, and to monitor avalanche activity in a given area in view of avalanche forecasting. Several automated or semi-automated detection technologies have been developed in the past among which infrasound-based detection is the most promising for regional-scale avalanche monitoring. However, due to significant ambient noise content in infrasonic signals, e.g. from atmospheric processes or airplanes, fully automated and reliable avalanche detection has been very challenging. Signal processing is highly critical and strongly affects detection accuracy. Here, a robust detection method by using supervised machine learning is introduced. Machine learning algorithms can take into account multiple signal features and statistically optimize the classification task. We analyzed infrasound data with concurrent visual avalanche observations from the test site Lavin (Eastern Swiss Alps) for the winter of 2011–2012. A support vector machine was trained by using training data from the first half of the winter season and the accuracy was tested on data from the second half of the season. A significant reduction of false detections, from 65% to 10%, was achieved compared to a threshold-based classifier provided by the sensor manufacturer. The proposed method enables reliable assessment of the avalanche activity in the surroundings of the system and paves the way towards robust and fully automated avalanche detection using infrasonic systems.}
}

@article{Lawine:2019,
url = {https://austria-forum.org/af/AustriaWiki/Lawine?version=3}, 
author = {Verified by Hermann Maurer}, 
institution = {TU Graz},
version = {3},
urldate = {2022-01-15},
year = {2019}
}






@article{CAI201870,
title = {Feature selection in machine learning: A new perspective},
journal = {Neurocomputing},
volume = {300},
pages = {70-79},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.11.077},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218302911},
author = {Jie Cai and Jiawei Luo and Shulin Wang and Sheng Yang},
keywords = {Feature selection, Dimensionality reduction, Machine learning, Data mining},
abstract = {High-dimensional data analysis is a challenge for researchers and engineers in the fields of machine learning and data mining. Feature selection provides an effective way to solve this problem by removing irrelevant and redundant data, which can reduce computation time, improve learning accuracy, and facilitate a better understanding for the learning model or data. In this study, we discuss several frequently-used evaluation measures for feature selection, and then survey supervised, unsupervised, and semi-supervised feature selection methods, which are widely applied in machine learning problems, such as classification and clustering. Lastly, future challenges about feature selection are discussed.}
}



@article{Harvey:2016,
title = {Statistical Nowcast of Avalanche Activity at the Regional Scale},
author = {Stephan Harvey, Alec van Herwijnen, Bettina Richter},
year = {2016},
abstract = {Forecasting natural avalanche activity is challenging. Events are relatively rare and several contributory factors affecting the formation of dry- or wet-snow avalanches have to be evaluated. In contrast to previous statistical avalanche forecast models which focus on specific avalanche types or small scales, in this study we developed a model to predict avalanche days for an entire winter season at the regional scale. We therefore analysed an avalanche catalogue consisting of observed avalanches in the region of Davos, Switzerland, over the last 13 years (2003/04 to 2015/16). In combination with data from an automatic weather station and simulated snow cover properties from the model SNOWPACK, we trained random forest models by applying different methods to predict avalanche days. Overall, the predictive performance was in line with other similar studies. However, substantial differences in performance were observed among the 13 winter seasons. Surprisingly, the performance of models without snow cover data from the SNOWPACK simulations was very similar. These results suggest that there is no strong correlation between avalanche activity and snow cover properties, highlighting the limitations of obtained avalanche activity data through visual observations. While more work is still required, the reasonable performance of our statistical model to predict avalanche days show that automatically predicting regional avalanche activity using an automatic weather stations is feasible.},
url = {https://arc.lib.montana.edu/snow-science/item/2437}
}


@article{Pozdnoukhov:2008,
title={Applying machine learning methods to avalanche forecasting},
abstract={Avalanche forecasting is a complex process involving the assimilation of multiple data sources to make predictions over varying spatial and temporal resolutions. Numerically assisted forecasting often uses nearest-neighbour methods (NN), which are known to have limitations when dealing with high-dimensional data. We apply support vector machines (SVMs) to a dataset from Lochaber, Scotland, UK, to assess their applicability in avalanche forecasting. SVMs belong to a family of theoretically based techniques from machine learning and are designed to deal with high-dimensional data. Initial experiments showed that SVMs gave results that were comparable with NN for categorical and probabilistic forecasts. Experiments utilizing the ability of SVMs to deal with high dimensionality in producing a spatial forecast show promise, but require further work.},
volume={49},
DOI={10.3189/172756408787814870}, 
journal={Annals of Glaciology}, 
publisher={Cambridge University Press}, 
author={Pozdnoukhov, A. and Purves, R.S. and Kanevski, M.}, 
year={2008},
pages={107–113}
}













