\documentclass[../masterarbeit.tex]{subfiles}
\begin{document}
	























\section{Related Work}
In the context of avalanche risk prediction, several studies have already been conducted. Machine learning methods have been applied for this purpose. The data sets, used for these studies, usually consist of avalanche-related data in combination with meteorological or topographic data and eventually both recorded from smaller mountain areas, which were used as case studies. 

In the alps a dataset of avalanche events from the area around Davos, Swizerland \textcite[]{Harvey:2016} over the last 13 years is one example for these case studies. The study about the data from Davos aimed to predict the days in a winter season on which many avalanches occur for a whole winter season.
To get the Meteorological\footnote{ "Meteorology is the study of the physical and chemical phenomena and processes in the atmosphere and their interactions with the earth's surface." \autocite[]{dwd:2022} } Data for their study, the Team form the SLF, Swizerland used the data from an automatic weather station.
The authors combined these data with recorded snow avalanche events in the region of Davos and merged the simulated snowpack properties, like new snow depth, liquid water content, Stability indices, critical crack length, and the hand hardness, of the SNOWPACK model onto these data to get a dataset. For the predictions, the Team trained a Random Forest\footnote{ "Random Forest is a robust machine learning algorithm that can be used for a variety of tasks including regression and classification. It is an ensemble method, meaning that a random forest model is made up of a large number of small decision trees, called estimators, which each produce their own predictions. The random forest model combines the predictions of the estimators to produce a more accurate prediction." \autocite{DeepAI:2022}}  machine learning model with the final dataset. Before training the Random Forrest, the authors subdivided the dataset into five groups to avoid overfitting. Each of these groups defines which criteria distinguish an avalanche day from a non-avalanche day, for a specified avalanche type. The five groups are divided into New Snow avalanches, Wet snow 1 avalanches, Wet snow 2 avalanches, Wind drift avalanches and Everything else. \autocite[]{Harvey:2016}\\
The authors tried five different approaches, all including Random Forrest machine learning models, and validated the results after that.
For the first approach the number of features for each group is reduced by applying classification trees. Then, one random forest per group is trained with their data and the prediction of the groups per day is summed.
The second method is likely the same as the first one without reducing the features of the groups.
In the third the authors applied the random forest onto all 58 features of the dataset without separating into the five groups.
The fourth attempt is same as the third, but all avalanche days which do not meet the criteria of the new snow, wet snow 1 or wet snow 2 groups are considered non-avalanche days.
In the last method the random forest is only applied on avalanches of type new snow and measured meteorological data. \autocite[]{Harvey:2016}\\
One finding of the resulting study is that the predictions without the snowpack factors are just as good as those without this additional data. Furthermore, they concluded that their prediction attempts were severely limited by inaccurate in the visual observed avalanche activity data, the biased avalanche-related data and by the fact that the spatial scale is too large for their models. The Threshold, which they did use for the study, is too different, as it allowed up to 10 large avalanches for one day but also 1 medium, for the same value. They came to the result that forecasting on a small spatial scale using only one avalanche warning system could work well and could be a good aid for avalanche hazard forecasting services. \autocite[]{Harvey:2016}\\~\\
 
For another study, with the name: "Snow avalanche hazard prediction using machine learning methods" \textcite[]{Bahram:2019}, avalanche hazard maps were created using predictions from machine learning methods. The space around the watershed of Karaj, Iran is used for the case study of this paper. Support Vector Machines (SVM), which are described in detail in section 3.2.2 of this work as well as Multivariate Discriminant Analysis (MDA), which are an extension to the Linear Discriminant Analysis (LDA) mentioned in section 3.2.3 of this thesis, have been used as machnine learning techniques in this study. The goal of the study is to evaluate the performance of the two machine learning methods SVM and MDA for the prediction of snow avalanches. \autocite[]{Bahram:2019} \\
The dataset which is used in that study is created with three different main categories of data, including a series of meteorological data, a map of the avalanche occurrence and terrain-related data. A snow avalanche inventory map is created for the study by mapping the location of the snow avalanches, which were collected by field observations, onto google maps and confirming it by field surveys. Topographical\footnote{Topography is a branch of cartography and describes the characteristics of the earth's surface \textcite[]{wortbedeutung_topografie:2022}.} data like slopes, elevation, lithological and morphometric structures and 91 avalanche line locations were recorded while this process. The training of the machine learning models is done by using these locations as the dependent variable and 14 features as predictor variables. The Data is divided by an 70 to 30 ratio into a training and a testing set. To analyze the relative performance of the variables, the jackknife method is used, where the machine learning models are trained iteratively as many times as there are features in the set and one variable is removed at each iteration. This allows to investigate how important the removed variable is for the prediction quality. \autocite[]{Bahram:2019} \\
\begin{table}
    \centering
    \begin{tabular}{|l|l|l|l|l|}
    \hline
        Statistic & Training dataset & ~ & Testing dataset & ~ \\ \hline
        ~ & SVM & MDA & SVM & MDA \\ \hline
        Accuracy & 0.90 & 0.87 & 0.83 & 0.85 \\ \hline
        Bias & 1.11 & 1.16 & 1.11 & 1.07 \\ \hline
        POD & 0.95 & 0.95 & 0.89 & 0.89 \\ \hline
        FAR & 0.14 & 0.18 & 0.20 & 0.17 \\ \hline
        CSI & 0.82 & 0.79 & 0.73 & 0.75 \\ \hline
        HSS & 0.80 & 0.75 & 0.67 & 0.70 \\ \hline
    \end{tabular}
    \caption{The tabulation of the evaluation metrics from the study "Snow avalanche hazard prediction using machine learning methods"}
    \source{\autocite[]{Bahram:2019}}
\end{table}
Resulting from the jackknife method, the performance of the MDA is more sensible than the SVM, as the performance of the MDA decreased by removing one feature from the training data. Another result of the study is that avalanches seem to slide out mainly in the vicinity of streams. In addition, Multivariate Discriminant Analysis performed better in predicting avalanche danger compared to Suppport Vector Machines. Both methods produced results with an accuracy of 0.83 for the Suppport Vector Machines and 0.85 for the Multivariate Discriminant Analysis. The complete list of the study's evaluation metrics can be found in table 1.
The study also showed for both algorithms, that the altitude has no relevant effect on the prediction of avalanches. The recorded locations had a sea level between 1911m and 3396m. Also ROC-curve in combination with the AUC statistics, which is described in detail in chapter 3.4.4, were created in context of this study to evaluate the two machine learning models. The MDA resulted in an AUC-score of 0.912 and the value of the AUC statistic of the SVM is 0.942. \autocite[]{Bahram:2019} \\~\\

Thomas Thüring, Marcel Schoch, Alec van Herwijnen and Jürg Schweizer \textcite[]{THURING201560} also attempted to predict avalanches automatically using supervised machine learning methods. The goal of the study is to determine by machine learning whether the infrasonic sensor\footnote{Infrasonic sensors are avalanche detection systems, which can monitore avalanche activity of artificially triggered or natural avalanches in the range of 3 to 5km \textcite[]{wyssenavalanche:2022}. } array data belongs to an avalanche or not. \autocite[]{THURING201560} \\
The data area for the case study is around Lavin, switzerland in the east swiss alps for the winter of 2011-2012. Also in this study a Support Vector Machine are trained with the data. For the training set they used 26 days with 29 avalanche events and for the test set 73 days with 30 avalanche events based on the information of an infrasonic sensor. For the evaluation and optimization of the Support Vector Machine model, a 10-fold cross validation is used by the authors of the article. \autocite[]{THURING201560} \\
The authors managed to reduce the false predictions, compared to the threshold-based classifier, which is provided by the manufacturer of the infrasonic sensors, by training the SVM from 65\% to 10\%. The classification accuracy of the Support Vector Machine is 91.4\% for this study.  \autocite[]{THURING201560} \\~\\

Pozdnoukhov, A. and Purves, R.S. and Kanevski, M., attempt to create forecasts for a period of several days for avalanches probabilities, by the use of machine learning methods in their article "Applying machine learning methods to avalanche forecasting" \textcite[]{Pozdnoukhov:2008}.  \\
Just like in the studies mentioned before, the authors of this study use Support Vector Machines as classifier. For the study, the authors compare the performance of the SVMs to the established Nearest Neighbors models. \autocite[]{Pozdnoukhov:2008} \\
The Dataset, which is used to train the algorithm refers to an area around Lochaber, Scotland, UK, on which all mountains are below 1300m elevation. The set is a combination of ten meteorological and snowpack related variables on the basis of daily measurements with data from two previous days. This combination creates a set of 30 features. For the creation of the dataset, the avalanche forecasting expert for the Lochaber region is also consulted and a number of expert features were added to the dataset. The final dataset consisted of 44 features. 
 After data preprocessing and iterative feature selection with the SVM dataset is then reduced from 44 to 20 predictor variables and 1835 samples. In total the dataset included about 700 avalanches for 49 avalanche lines. \autocite[]{Pozdnoukhov:2008} \\
 For the training of the SVM, the dataset is divided into a train and a test set. The train set is the data for the winters from 1991-2000, which included 1123 samples. The test set included 712 rows for the winters of 2001-2007. 
The performance of the Support Vector Machines is compared to Nearest Neighbors machine learning methods, which are established methods for this field. The predicted probabilities of the SVM are close to the empirical probabilities for avalanche events. This observation can be seen especially at high probabilities. The lower the probabilities are, the less accurate they are. For another experiment, the authors added for each of the 49 avalanche lines the factors: constant meteorological and snow cover for the region, altitude, aspect ratio and gradient to each day in the data set. This was done to undertake a spatial avalanche forecast and project it onto a digital elevation model of the region. \autocite[]{Pozdnoukhov:2008} \\
The conclusion of this study mentioned, that the Support Vector Machine at its optimum thresolds of 0.5 is broadly comparable to the Nearest Neighbors models, applied to the same dataset, but not significantly better. On the other hand, a finding of the study was that, the Nearest Neighbors models need a high number of neighbors to deliver as good results as the SVM. For this reason, the Nearest Neighbors method produces similarly good results as the SVM when 20 nearest neighbors are used, but shows a significant decrease in performance when 10 or fewer nearest neighbors are used. This can be attributed to the high dimensionality of the data needed for avalanche prediction. Since the Nearest Neighbors method is worse at handling high dimensional data compared to the SVM. For this purpose the authors see the potential of Support Vector Machines in future approaches of predicting avalanche events. \autocite[]{Pozdnoukhov:2008} \\~\\

Anuj Tiwari, Arun G., Bramha Dutt, Vishwakarma \textcite[]{Tiwari:2021} investigate in the context of their paper how the effectiveness of SVMs in predicting avalanches is improved by parameter importance assessment (PIA)\footnote{ "Parameter importance assessment (PIA) or feature selection (FS) is an essential step in susceptibility modeling applications. By eliminating irrelevant, and noisy parameters from the input datasets, PIA solves the issues of redundant information processing and enhances the accuracy of the model" \autocite[]{Tiwari:2021} }.
Similar to the study of Bahram Choubin, Moslem Borji, Amir Mosavi, Farzaneh Sajedi-Hosseini, Vijay P.Singh, Shahaboddin Shamshirband \textcite[]{Bahram:2019}, the main aim of this study is to generate a very accurate Avalanche susceptibility map (ASM)\footnote{ "Avalanche susceptibility map (ASM) is one of the essential information in spatial planning for avalanche prone areas. It gives a description about spatial probability of avalanches." \autocite[]{Tiwari:2021}}, 
which indicates the avalanche susceptibility, out of a prediction model based on a SVM and a PIA. \autocite[]{Tiwari:2021} \\
The authors define the idea behind the study as follows:
\begin{quote}
	"The underlying hypothesis is that non-linear relationships between past avalanche occurrences and influencing parameters can be used for avalanche susceptibility modeling. " \autocite[]{Tiwari:2021} 
\end{quote}
The study area for the case study is an avalance prone area in India which covers the greater Himalayan mountain range. The area has a mean elevation of 4430m above sea level and includes glacier covered mountains. The avalanche inventory map, which is used for the training and validation of the machine learning models, includes 114 avalanche locations and the same number of randomly picked non-avalanche locations which are picked from a set of location like urban settlements, water bodies, or crop land, where no avalanches can occur. The authors split the created avalanche inventory map into a randomly selected 70 to 30 ratio train and validation set.
The training data for the study is a combination of eleven parameters, which are of the meteorological and topographical data types. \autocite[]{Tiwari:2021} \\
To get the parameter importance, the Boruta\footnote{"Boruta is a parameter importance assessment (PIA) and influence analysis algorithm.[...]. With RF as the fundamental instrument method, Boruta integrates the association between input parameters and iteratively eliminates the unimportant ones." \autocite[]{Tiwari:2021}} algorithm was used as PIA. As mentioned before, trained machine learning algorithms in the study SVMs with linear, poynomial, sigmoid and RBF kernel functions.
For the Validation of the study, the authors chose the Receiver Operating Characteristic\footnote{"ROC is one of the most preferred techniques for describing the quality of susceptibility modeling techniques (Fawcett, 2006). It depicts the true positive rate on the y-axis and the false positive rate on the x-axis." \autocite[]{Tiwari:2021}} (ROC) curve and the Area Under the Curve\footnote{todo} (AUC) statistic. The combination AUC-ROC technique is used to rate the accuracy of the algorithm results. The AUC statistic showed \autocite[]{Tiwari:2021} \\
The resulting values of AUC statistic showed respectively the use of selected parameters (the second value) the following values for the kernel functions used as part of the SVM: linear 88.2\%, polynomial 91.6\%, sigmoid 46.3\% and RBF 91.5\% for the use of all features and linear 88.0\%, polynomial 92.1\%, sigmoid 44.6\% and RBF 93.4\% when using selected parameters. \\
The results of this study in terms of the importance of each parameter for the creation of an ASM show different results to the very similar study from article "Snow avalanche hazard prediction using machine learning methods" \textcite[]{Bahram:2019}. For example, in this study elevation is ranked as the third most important parameter, while in the similar study elevation is ranked as the last of the series.  \autocite[]{Tiwari:2021} \autocite[]{Bahram:2019} \\~\\

Hong Wen and Xiyong Wu and Xin Liao and Dong Wang and Kaiyang Huang and Bernd Wünnemann \textcite[]{WEN2022103535} applied a set of machine learning methods for the purpose of snow avalanche susceptibility mapping. They used an area in Parlung Tsangpo in souteastern Tibet for their case study and collected a set of 381 snow avalanches through seven field investigations. The Samples were marked with the coordinates of the location and the range  of the starting points of the avalanches. 
The 381 locations were divided into a training set of 305 avalanche locations and a validation set with 76 locations. This makes a 80\% to 20\% train test ratio.
The authors also created a set of sample considering the polygon attributes with 27596 points in 120m intervals within the starting zones and the same number of random non-avalanche samples, picked from outside of the avalanche zones. 
A number of specific conditional and topographical variables, such as Elevation, Slope, Aspect, Roughness, average annual snow fall, average temperature in January Maximum snow depth and the distance to rivers were added to the set of starting zones, to be able to present a generalized form, of the many factors that influence the complex process of the formation of a snow avalanche. \autocite[]{WEN2022103535} \\
For the modeling, the team used the four machine learning methods: Support Vector Machine (SVM), K-nearest neighbors\footnote{"KNN is a method to classify observations according to the similarity between observations and other observations, which is a mature method in theory. The idea of this method is: if most of the k most similar samples in the feature space belong to a certain category, then the sample also belongs to this category." \autocite[]{WEN2022103535} } (KNN), Classification and Regression Tree\footnote{"The Classification and Regression Tree algorithm is a decision tree that can be used to predict or classify future observations." \autocite[]{WEN2022103535} } (CART) and  Multilayer perceptron\footnote{"MLP is a feed-forward artificial neural network model, which maps multiple input data sets to a single output data set. Each node in the Neural Network is a perceptron, which models the basic function of neurons in the biological neural network." \autocite[]{WEN2022103535} } (MLP). \autocite[]{WEN2022103535} \\
The importance of the conditional factor features were calculated by training a SVM with the samples. as a result, all features with an importance of less than 3\%, such as the average annual snowfall days, were removed from the sample set. The authors also divided the whole study area into 845263 rasters of a 120m x 120m size and trained the machine learning algorithms on the whole set. The prediction results of the algorithms were imported into a GIS and projected onto maps of the study area. \autocite[]{WEN2022103535} \\
The performance of the models have been evaluated by the Kappa coefficient\footnote{"Kappa coefficient test is a method of using confusion matrix to test the consistency between model results and actual observations, also known as consistency test. Kappa coefficient test is to use confusion matrix to calculate kappa coefficient, the coefficient is between −1 and 1, usually greater than 0. The larger the value, the higher the accuracy of the evaluation model is." \autocite[]{WEN2022103535} } and the ROC curve. 
The performance evaluation of the machine learning models with the Kappa coefficient showed that all models made good predictions. According to the order of prediction quality resulting from the evaluation with the Kappa coefficient, the SVM performs best, followed by the CART, third the MLP and last the KNN. In the evaluation with the AUC statistic, the result was that the SVM was again in first place, followed by the MLP, in third place the KNN and in last place the CART, whereby the first three models achieved an AUC value of over 0.9 and the CART a value just below 0.9, and thus high values were achieved for all.
As conclusion, the SVM is, with an AUC value of 0.918 the most robust machine learning model of the study and the authors concluded that their approach, for the creation of avalanche susceptibility index maps, achieves accurate and useful results and this method is promising for future applications. \autocite[]{WEN2022103535} \\

In The Paper "A data efficient machine learning model for autonomous operational avalanche forecasting" \textcite[]{nhess-2021-106} from the year 2021, Chawla, M. and Singh, A. describes their study about their approach for an data efficient forecast of snow avalanche events by the use of a Random Forrest machine learning model. The model is supposed to perform a binary classification into the classes "avalanche" and "non-avalanche", based on snow parameters and meteorological variables. 
The geographical area of this study is the Bandipore-Gurez (BG) sector at the tip of the north-west Indian Himalayan Mountains. The area observation includes over 100 avalanche paths, whose starting zones are located at the altitude between 2350m and 4800m above sea level. The authors got their Snow- and Meteorological parameters from a snow-meteorological observatory, which is located new Kanzalwan at an elevation of 2440m. The dataset created by the team was assembled from two tables. The first table contains the meteorological and snow related features provided by the observatory. The second table consists of additional parameters derived from the features in the first table. The features from the second table represent the snow related features, the number of avalanches occurred and meteorological data from the last two to ten days. The dataset used to train the algorithm includes the three winter seasons from 2010 to 2013 of the meteorological, snow and avalanche event features. The authors want to demonstrate the data efficiency of their approach with the size of the sample set used to train the model.  Different to the most studies mentioned in this chapter, the size of the test set in this study is larger than the training data sample set. It includes the four winter seasons from 2013 to 2017. \autocite[]{nhess-2021-106} \\
The forecast, which was made for the study, distinguishes for the whole area into two classes 0 for non-avalanche days and 1 for avalanche days \textcite[]{nhess-2021-106}. Therefore, no slope specific forecasts are made, but similar to the study from Davos in Switzerland \textcite[]{Harvey:2016}, avalanche days are predicted for the entire area. \\
The authors describe in their paper a problem they encountered in their original data set. The problem is that the number of avalanche days (25\%) is much lower than the number of non-avalanche days (75\%). From this unbalanced distribution they conclude that the classification system model will have a bias to predict more non-avalanche days. The paper describes to solve this problem. The first is a cost-correcting classifier that gives higher weight to the samples from minority classes. The second approach they describe randomly removes samples from the majority class or artificially adds entries to the minority class. However, according to the authors, this can lead to overfitting. The method, used in the study is based the second mentioned technique but instead of removing random samples of the majority class, the authors removed samples based on domain specific knowledge. So as a result all data rows, in which are avalanche events are unlikely because of an absence of snow cover were removed from the training set. As an example the authors removed all rows where the snow height was below 0.50m. The consequence of this filtering method is that the classification can also not be applied to days with a snow height below 0.5m. \autocite[]{nhess-2021-106} \\
The Random Forest classification model is trained and validated by a five fold cross-validation. The authors optimized the two input parameters of the Random Forest model (maximum depth and number of trees) by performing a series of experiments in which every possible combination of the values 2, 3, 4, 5 for maximum depth and 2000, 5000, 10000, 20000 for number of trees were performed on the model. Based on the results of the test series, the authors used 3 for maximum depth and 5000 for the number of trees parameters. \autocite[]{nhess-2021-106} \\
One result of the study showed, that the snow height, the new snow fallen in the last ten days and the wind speed were important indicators for the forecast of an avalanche-day. In summary, the authors found that the Random Forrest is suitable for the creation of an autonomous data-efficient snow avalanche forecast and provides good results. \autocite[]{nhess-2021-106} \\

















\end{document}