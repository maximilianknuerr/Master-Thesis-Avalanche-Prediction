\documentclass[../masterarbeit.tex]{subfiles}
\begin{document}
	




\subsection{Model training and evaluation}
In this chapter, the training phase and the evaluation of the three machine learning classification models Logistic Regression, Linear Discriminant Analysis and Support Vector Machine are explained. The structure of the models and their evaluation will be discussed in more detail. The three machine learning models are trained and evaluated in the order Logistic Regression, Linear Discriminants Analysis. The three models were trained on the respective data sets optimized for the models, which are described before in section 4.2.2. A confusion matrix was created for every model as well as cross-validated accuracy, precision and recall metric. In addition, cross validated ROC curves were created for the Logistic Regression, LDA and SVM models. Before training and evaluating the algorithms on the optimized sets, the datasets were standardized with the StandardScaler \textcite[]{Sklearn_StandardScaler:2022} function mentioned in section 3.1 about data preprocessing.  \\~\\



The training and evaluation phase of the Logistic Regression model is described as the first of the three classification models. The Logistic Regression model from the Sklearn.linear\_model library \textcite[]{Scikit-learn-logistic-regression:2022} was trained with its default parameters. \\
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{confusion_matrix_LR.png}
    \source{created by the author}
    \caption{The confusion matrix for the Logistic Regression model.}
\end{figure}
In order to gain a direct insight into the predictions of the machine learning model, the confusion matrix, which is shown in figure 18, was created for the model in the course of the study. The confusion matrix represents the four output types of the binary classification model as mentioned in chapter 3.4. In the case of this study the binary states are "Avalanche" and "Non-avalanche". The confusion matrix in figure 18 presents the predicted states on the Y-axis and the true states on the X-axis. For the creation of the confusion matrix the train test split function from the Python library sklearn.model\_selection \textcite[]{Scikit-learn-train-test-split:2022} was performed on the data set with a train test ratio of 75\% training set to 25\% validation set. So in total 5263 training samples and 1758 test samples are used. To create the confusion matrix, the plot function ConfusionMatrixDisplay \textcite[]{Scikit-learn-confusion-matrix:2022} from the library Sklearn.metrics is used. In the top left corner of the matrix the 899 True Negative predicted Non-avalanches are represented. 194 actual Non-avalanches were predicted as Avalanches shown in the top right quarter of the matrix. The Logistic Regression Model also predicted 325 Avalanches as Non-avalanches and 338 actual Avalanche samples as Avalanches. So the total number of samples falsely predicted by the Logistic Regression model is 519. The total number of correctly predicted samples is 1239. The number of Avalanche samples included in the test set is 663 and the number of Non-avalanche samples is 1093. As the confusion matrix shows, the percentage of correctly determined avalanches is smaller compared to the percentage of correctly determined non-avalanche samples. This could indicate a bias toward the non-avalanche samples caused by the fact that the dataset includes more Non-avalanche samples than Avalanche samples, as mentioned in chapter 4.1.5. \\~\\
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{confusion_matrix_LDA.png}
    \source{created by the author}
    \caption{The confusion matrix for the Linear Discriminant Analysis model.}
\end{figure}
The second model trained and evaluated is the Linear Discriminant Analysis model.
For this task, the LDA model from the sklearn.discriminant\_analysis \textcite[]{Scikit-learn-lda:2022} is used. The model was also trained on with the default parameters defined by the library. For all following training and evaluation processes of the model, the data set optimized for the LDA by the genetic algorithm, which is listed in Table 7, was used. \\
The confusion matrix represented in figure 19 shows was created for the purpose of getting an overview over the predictions made by the Linear Discriminant Analysis model. The confusion matrix was created with the same function as that one for the Logistic Regression model, as well as the 75\% to 25\% split for the train and validation dataset. The number of Non-avalanche samples of the test set is 1093 and the number of Avalanches 663, which are exactly the same numbers as for the Logistic Regression model.
The number of True-Positive predicted samples shown in that confusion matrix is 381. The sum of Avalanche samples which were predicted as Non-avalanche ones is 282. Furthermore, the number of non-avalanche samples predicted by the Linear Discriminant Analysis model True-Negative is 906. In the upper right quarter of the confusion matrix, the incorrectly predicted non-avalanches are plotted, with the number of False-Positive values at 194. As can be seen the number of True-Positive predicted samples is larger  and the number True-Negative predicted samples is similar compared to the predictions of the Logistic Regression model. It is especially with the prediction of the avalanche samples further away from coincidence. This indicates that there may be sufficient information in the data to predict snow avalanches for topographically defined mountain slopes. In total 1287 samples have been predicted correctly by the LDA model. The number is slightly higher than that one of the Logistic Regression, because the LDA predicted more Avalanche samples correctly.\\~\\
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{confusion_matrix_SVM.png}
    \source{created by the author}
    \caption{The confusion matrix for the Support Vector Machine model.}
\end{figure}
The Support Vector Machine is the last model trained for the study of this thesis. The SVM implementation used is the C-Support Vector Classification (SVC) \textcite[]{Scikit-learn-svc:2022} from the Sklearn.svm library. The parameters used for the model are also the default values from the documentation. The three parameters "kernel", "C" and "gamma" have an influence on the quality of the predictions of the model. The "kernel" specifies the kernel function, which is used by the algorithm. The default kernel used in the SVC sklearn implementation is the  Radial Basis Function (RBF) kernel. \autocite[]{Scikit-learn-svc:2022} The gamma value describes how far the influence of a single training sample extends, with small values representing "far" and large values representing "close" \textcite[]{Scikit-learn-rbf-para:2022}. The default value of this parameter is "scale", which uses \(1 / (n_features * X.var())\) as value for the gamma parameter. The default value of the "C" parameter is 1.0. \autocite{Scikit-learn-svc:2022} The "C" parameter acts as a regularization parameter of the SVM. Through this parameter, the correct classification of the training examples is balanced against maximizing the margin of the decision function. \autocite[]{Scikit-learn-rbf-para:2022} \\
Also in the case of the SVM model, the confusion matrix was created using a 75\% to 25\% train test ratio of the data. In addition, the number of avalanche and non-avalanche samples in the training and test set is the same as in the previous two models. The first thing to notice when looking at the confusion matrix in Figure 20, which was created using the SVM model, is the color difference between the correctly and incorrectly predicted samples. The value of the correctly predicted avalanche samples is the highest of the three models at 437, which makes the square stand out more from the one to the left, which represents the false negative predicted values, than in the confusion matrix for the logistic regression model. The number of False-Negative predicted values shown in the bottom left corner of the confusion matrix is 226, which is 99 samples less than with the Logistic Regression model and 56 less then the LDA. The present difference between correctly and incorrectly predicted avalanche samples suggests that the predictions are not coincidental and that the data contain information for the prediction of avalanches. The sum of samples predicted as True-Negative is 934. In addition, 159 non-avalanche samples were predicted to be avalanches. In total, 1371 samples have been predicted correctly by the SVM model. So it predicted more samples correctly than the LDA and the Logistic Regression models. The model also predicted 385 samples incorrectly which are 84 samples less than the LDA model. \\~\\













To gain more information about the quality of the predictions, made by the three machine learning models, a 10-fold cross-validation was performed on each of the models and a series of the evaluation metrics accuracy, recall and precision were created in conjunction with them. As explained in chapter 3.4.5, cross-validation offers the possibility to perform an extensive validation over the whole dataset and at the same time to use a large part of the dataset for the training of the machine learning models at each iteration. So the resulting metrics are more representative for the quality of the predictions than the 75\% to 25\% train test split made for the confusion matrices before. For each of the resulting metrics, the maximum, minimum, and average values that occurred during the 10-fold cross-validation are represented in table 8. The first score which is represented in table 8 is the accuracy score. As mentioned in section 3.4.1, the accuracy score represents the total number of correctly predicted samples compared to the total number of samples. The average accuracy score is 0.735 for the Logistic Regression model, 0.732 for the LDA model and 0.754 for the SVM model. So the values are similar for all three models, but that one of the SVM is higher than the others. The maximum accuracy is 0.806 for the Logistic Regression, 0.800 for the LDA and 0.803 for the SVM. In this case the values of all three models are similar to each other. The values of the minimum accuracy in the same order as before are 0.678, 0.690, 0.713. As can be seen, the SVM has the highest minimum accuracy, the LDA follows and last is the Logistic Regression. Causing the fact that there are less Avalanche samples included in the datasets than Non-avalanches, the balanced accuracy score is also calculated for the three models. The average balanced accuracy score is 0.705 for the Logistic Regression model. This value is 0.030 smaller than the normal accuracy score for this model. For the Linear Discriminant Analysis model the balanced accuracy score is 0.700, which is 0.032 smaller than the average accuracy score for the same model. The value of the average balanced accuracy for the SVM model is 0.724, which is the highest value of the three. Similar to the balanced accuracy score of the two models Logistic Regression and LDA it is about 0.030 smaller than the accuracy score for the model. As already mentioned in chapter 3.4.1 about the accuracy score, the value of the balanced accuracy score is often smaller than that one of the accuracy score in the case of an unbalanced data set. In contrast to the most previous metric values, the value of the maximum balanced accuracy score for the Logistic Regression model is the largest of the three models at 0.788. The value for the LDA is 0.765 and for the SVM 0.779. However, the value of the minimum balanced accuracy score for the Logistic Regression model is also the lowest with 0.636 compared to 0.659 and 0.663 for the LDA and SVM. \\~\\
\begin{table}[!ht]
    \centering
    \begin{tabular}{|l|l|l|l|}
    \hline
         & Logistic Regression & LDA & SVM \\ \hline
        Average accuracy & 0.735356 & 0.732791 & 0.754446 \\ \hline
        Max accuracy & 0.806268 & 0.800853 & 0.803419 \\ \hline
        Min accuracy & 0.678063 & 0.690883 & 0.713675 \\ \hline
        Average balanced accuracy & 0.705463 & 0.700595 & 0.724890 \\ \hline
        Max balanced accuracy & 0.788748 & 0.765140 & 0.779399 \\ \hline
        Min balanced accuracy & 0.636473 & 0.659482 & 0.663706 \\ \hline
        Average precision & 0.692394 & 0.693510 & 0.720818 \\ \hline
        Max precision & 0.831579 & 0.825000 & 0.809278 \\ \hline
        Min precision & 0.570571 & 0.587859 & 0.613636 \\ \hline
        Average recall & 0.577125 & 0.562296 & 0.597944 \\ \hline
        Max recall & 0.755556 & 0.703704 & 0.762963 \\ \hline
        Min recall & 0.379182 & 0.425926 & 0.449814 \\ \hline
    \end{tabular}
    \caption{A tabular arrangement showing the results of training the machine learning models and evaluating them using the metrics Accuracy, Precision and Recall in the course of 10-fold cross-validations.}
\end{table}
Another evaluation metric calculated in this evaluation process and represented in table 8 is the precision score. The value of the average precision score over the 10-fold cross-validation, calculated for the Logistic Regression model, is 0.692. For the LDA the average of the score is 0.693, which is similar to the Logistic Regression model. The SVM has the highest average precision score of 0.720 over the ten iterations of cross validation. The metric evaluates the proportion of positively predicted samples that are actually positive. The Logistic Regression model had both the highest maximum precision score of 0.831 and the lowest minimum precision score of 0.570 of the three models. The next lower maximum precision score of 0.825 and the following minimum precision score of 0.587. The SVM has the lowest maximum precision score of 0.809 and the highest minimum precision score of 0.613. As can be seen in the table, the maximum precision score of the SVM is lower than that of the other models, but the average value over the 10 iterations is higher than the scores of the other models. The last metric calculated in the course of the evaluation of the three machine learning models and shown in table 8 is the recall score. The score in the context of this work refers only to the avalanches and the proportion of avalanches that were correctly predicted. The value of the Logistic Regression models average recall is 0.577. For the LDA model the value of the score is 0.562 and for the SVM model it is 0.597. As can be seen all values are smaller than the average values of the other scores. But also all of these values are above chance. The minimum and maximum values of the recall in the cross validation of the three models drift from each other. Thus, the minimum value of the recall of the Logistic Regression model is 0.379, which is smaller than chance, which is 0.5, and the maximum value of 0.755 is similar to the average accuracy score and 0.376 larger than the minimum and thus almost twice as large. Also the LDAs maximum recall value is about 0.703 an its minimum is 0.425. Recently, the maximum and minimum recall values of the SVM model are also different with 0.762 and 0.449. While all of the maximum and average recall score values are above the chance value of 0.5, the three minimum values are all below the value. \\~\\

After that step the last evaluation step made in case of this study, are ROC-curves in combination with the Area under the curve (AUC) score. For the three machine learning models the ROC curve and AUC score is calculated during 10-fold cross-validations, to obtain representative validation values. The graphs represented in the figures 21, 22, 23 and 24 do all show a red striped straight line from \((0,0)\) to \((1,1)\). This line represents chance. So if the ROC-curve of a model is near to that line it is near to chance. The value of the area under the curve is 0.5. If the AUC value is below the chance, the model might have a false interpretation of the input data. A description of the ROC-curve and AUC value can be found in chapter 3.4.4. 
The three figures 21, 22 and 23 also show the standard deviation of the 10 ROC-curves created in the iterations of the cross-validation. The standard deviation is marked as light grey area in the graph.
Also the blue marked ROC-curve represents the mean ROC-curve of the 10-fold cross-validation iterations.
The ten ROC-curves of the cross-validation are presented in light colors as shown in the describtions of the graphs.
The 10-fold cross-validated ROC curves of the Logistic Regression model are represented in figure 21. The blue marked mean ROC-curve for this model has an AUC value of 0.80 and therefore falls just into the excellent category. As shown in the figure, the blue line of the mean ROC curve stands out from the red dashed line, which represents chance. This suggests that the predictions of the logistic regression model are not random. The value of the area under the ROC curve gives a balanced calculation and alternative to the prediction accuracy, as it contrasts the correctly predicted positive values against the falsely positively predicted values. Thus, the AUC score of the mean ROC curve of 0.80 corresponds to an 80 percent prediction accuracy, which is far above chance. In addition, all ROC curves of the 10-fold cross validation are above the red striped line directed at a 45 degree angle, which represents chance.  As well as all AUC values of these curves above the value of 0.5. For instance, the lowest AUC value of the ten ROC curves is 0.74 at folds 3 and 9, and the highest is 0.87 at iterations 0 and 2. The minimum value can be placed into the acceptable but the maximum value is also an excellent one. The standard deviation of the 10-fold cross-validation values of the area under the ROC-curves is  0.05. The low standard deviation, as well as the fact that the AUC values of all 10 iterations of the cross validation lie with a distance of at least 0.24 above the random line, suggests that the features of the data set contain enough information to make predictions using Logistic Regression models. \\
 











\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{ROC_AUC_LR.png}
    \source{created by the author}
    \caption{The ROC curve with AUC statistics with 10-fold cross-validation for the Logistic Regression model.}
\end{figure}

Figure 22 represents the 10-fold cross-validated ROC-curves and AUC values, calculated for the Linear Discriminant Analysis model. The graph is constructed like the graph of the ROC-curves of the Logistic Regression model. Similar to the Logistic Regression model, the value of the area under the mean ROC-curve of the Linear Discriminant Analysis model is 0.80, which can be assigned to the beginning of excellent or the end of acceptable. The associated curve, which is marked in blue in the figure, also stands out from the chance in its entirety. Also, all of the ten ROC curves of the cross-validation of the LDA model form above the random line. The AUC values are all above the chance, with a minimum value of 0.74 in the last iteration and a maximum of 0.86 in the folds 0 and 2. The minimum AUC value is rated as acceptable because it is between 0.7 and 0.8 and the maximum value can be classified as excellent, because it is between 0.8 and 0.9. The standard deviation of the 10-fold cross validation ROC-curve AUC values is similar to that one of the Logistic Regression model 0.04. Resulting from the Mean AUC score of 0.80, representing a prediction accuracy of 80 percent, in conjunction with the standard deviation of the 10 AUC values of the ROC curves of 0.04, indicates that the predictions of the Linear Discriminant Analysis model are not random. It also suggests that there are relationships between the features and the triggering of avalanches within the data set. \\


\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{ROC_AUC_LDA.png}
    \source{created by the author}
    \caption{The ROC curve with AUC statistics with 10-fold cross-validation for the LDA model.}
\end{figure}


The standard linear SVM is a discrete classifier so in terms of a roc curve it would just be a point.
The RBF kernel used as default for the SVC Implementation from Sklearn makes it possible to have a threshold and so also to get a ROC curve. For this study the SVC implementation is used with the default kernel RBF. The RBF kernel function performed best with an AUC statistic of 0.934 in the study from nuj Tiwari, Arun G., Bramha Dutt, Vishwakarma \textcite[]{Tiwari:2021} when used with a feature selected dataset, among kernel functions that can be used for SVM

Also for the SVM model, a 10-fold cross validation was used in the calculation of the ROC curve to ensure a representative evaluation. These are shown in Figure 23. 
The mean ROC curve of the cross-validation of the Support Vector machine model is also shown as a blue line in the figure. The AUC value of this curve is with the value of 0.82 slightly higher than that one of the other two machine learning models. As mentioned in chapter 3.4.4 about the ROC-curve and the AUC value, a AUC value greater than 0.8 and smaller than 0.9 is rated as excellent so in this case the AUC value of the mean ROC-curve is between 0.8 and 0.9. The 10 roc curves created while the cross-validation of the Support Vector Machine model, are are not too far apart from each other, as shown by the standard deviation highlighted in gray in Figure 23. Furthermore, the standard deviation of the AUC values is also 0.04 and is thus as large as the standard deviations of the AUC values resulting from the cross-validations for the other two models. The difference in the values in comparison to the other models is also shown by the single minimum value of 0.74, which is the same as the minimum value of the other two models. In this case it is followed by the value 0.79, which is near to the excellent classification while the second lowest AUC value for the LDA is 0.75 and for the Logistic Regression model an AUC value of 0.74, which are both in the middle of the acceptable range of AUC values. \\
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{ROC_AUC_SVM.png}
    \source{created by the author}
    \caption{The ROC curve with AUC statistics with 10-fold cross-validation for the SVM model.}
\end{figure}
In addition, the maximum AUC score of the 10-fold cross-validation of the SVM model with a value of 0.89 is at least 0.02 higher than the maximum values of the other two cross-validated models. Their maximum AUC values, as mentioned above, are 0.87 for the Logistic Regression Model and 0.86 for the LDA model. The maximum AUC value of the SVM model cross-validation is at the upper end of the excellent range. All ten roc curves also stand out strongly from the red dashed line, which represents randomness, with only minor deviations in the ROC-curve with the lowest AUC value. The mean ROC-curve with an AUC value of 0.82, which also represents an prediction accuracy of 82 percent, shows that the predictions made by the SVM model are not random and that it found correlations in the features of the dataset. \\
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{ROC_AUC_Comparison.png}
    \source{created by the author}
    \caption{A comparison of the ROC curve and AUC statistic for the Logistic Regression, LDA and SVM models.}
\end{figure}
In addition, three more ROC curves and AUC values were calculated for the three machine learning models without the use of 10-fold cross-validation and visualized in a fourth plot. These curves can be seen in Figure 24. The Datasets used for this evaluation ROC-curves are for for each algorithm the specially optimized subset. The dataset is split into a 75\% train and a 25\% validation set. This last ROC-curves show the differences between the three machine learning algorithms. The gap between the ROC-curve of the Support Vector Machine model and these of the Linear Discriminant Analysis model and the Logistic Regression model is visible in the graph. While the two ROC curves of the LDA and Logistic Regression models differ little from each other, the ROC curve of the SVM model stands out at a distance above the other two. The same is also reflected in the AUC values of the three ROC curves. The AUC value for the SVM model is 0.85 and is in the mid-excellent range. The AUC scores of the other two models are both 0.80 and thus on the borderline between acceptable and excellent. All three algorithms therefore provide usable results according to the ROC curves and associated AUC scores, while the SVM model stands out from the others in the direction of the true positive rate. The acceptable to excellent values of the AUC scores indicate that none of the three models could predict by chance and find correlations of features within the data set.



\end{document} 